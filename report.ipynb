{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Plankton are microorganisms that form the base of the aquatic food chain. Photosynthetic plankton also play a crucial role in the global carbon cycle, as well as producing much of the world's oxygen. Because of their importance to the marine ecosystem, monitoring the health of the plankton population is a key component of oceanic research. One method to monitor plankton populations over time is through in-situ imaging of individual planktonic organisms. In-situ monitoring allows for the collection of not just abundance data but also morphological information on various species of plankton. \n",
    "\n",
    "The Martha's Vineyard Coastal Observatory operates an imaging flow cytometer (the MVCO FlowCytobot) that operates continuously and takes photographs of individual plankton cells in the water column. The large amount of image data generated by this machine necessitates the development of automated methods to classify plankton images. The Woods Hole Oceanographic Institute which operates the FlowCytobot has released several datasets of expert labeled plankton images for the purpose of training machine learning models to classify plankton by species. The main dataset, WHOI-plankton contains >3.5 million labeled images of plankton from 103 classes. Unfortunately, the dataset is highly imbalanced, with 6 classes comprising up to 85% of the whole dataset. Imbalanced datasets can hamper the performance of machine learning models due to underfitting of training on rarer classes. One solution for imbalanced datasets is to augment the images of the rarer classes to balance the dataset.\n",
    "\n",
    "# Method \n",
    "\n",
    "In this notebook, I explored the use of a generative adversarial network (GAN) to generate synthetic images of plankton from the WHOI-plankton dataset. The synthetic images can be used to augment the training data for the rarer classes in the dataset. The GAN model was trained on a balanced subset of the WHOI-plankton dataset containing 22 classes and 6598 images. This dataset is called WHOI22. In addition, I used traditional image augmentation techniques to gradually replace the images of the WHOI22 dataset to evaluate the impace of image augmentation on transfer learning performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image examples\n",
    "\n",
    "Here are some examples of the images in the WHOI22 dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256)\n",
    "batch_size = 32\n",
    "def load_data(batch_size=batch_size):\n",
    "    train_data = keras.utils.image_dataset_from_directory(\"datasets/padded_training\",\n",
    "                                                            labels=\"inferred\",\n",
    "                                                            label_mode=\"categorical\",\n",
    "                                                            image_size=image_size,\n",
    "                                                            batch_size=batch_size)\n",
    "    test_data = keras.utils.image_dataset_from_directory(\"datasets/padded_testing\",\n",
    "                                                            labels=\"inferred\",\n",
    "                                                            label_mode=\"categorical\",\n",
    "                                                            image_size=image_size,\n",
    "                                                            batch_size=batch_size)\n",
    "    return train_data, test_data\n",
    "train_data, test_data = load_data()\n",
    "combined_data = train_data.concatenate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in combined_data.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(np.array(images[i]).astype(\"uint8\"))\n",
    "        plt.title(combined_data.class_names[tf.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "To benchmark the performance of training on the balanced WHOI22 dataset, I used a EfficientNetB7 model pre-trained on the \"imagenet\" dataset and performed transfer learning. Code is based on and inspired by the keras tutorial on transfer learning: https://keras.io/guides/transfer_learning/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "\n",
    "base_model = EfficientNetB7(\n",
    "    weights='imagenet',\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False\n",
    ")\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(256, 256, 3))\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = keras.layers.Dense(22)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This baseline model achieved an overall accuracy of ***TBD***, with average precision of ***TBD*** and average recall of ***TBD***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved model\n",
    "\n",
    "## Load predictions\n",
    "\n",
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "\n",
    "I created a function to augment a proportion of the images in the WHOI22 dataset and replace the original images with the augmented images. I evaluated the impact of image augmentation on the performance of the EfficientNetB7 model. Below is the code I used to create new augmented datasets, based on the keras tutorial (https://www.tensorflow.org/tutorials/images/data_augmentation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to augment dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display examples of augmented data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Images were downloaded from Olsen & Sosik 2007 (https://doi.org/10.4319/lom.2007.5.195) in tif format. I padded the images to a square aspect ratio with black pixels to 256x256 and saved as bmp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Function that takes a tiff image and pads it to the desired size (square) and returns a numpy array\n",
    "def pad_image(image, size):\n",
    "    # load the image\n",
    "    img = tif.imread(image)\n",
    "    # get image dimensions\n",
    "    x,y = img.shape\n",
    "    # calculate the padding\n",
    "    x_pad = size - x\n",
    "    y_pad = size - y\n",
    "    # check if padding is needed, if not, resize the image maintaining aspect ratio\n",
    "    if x_pad < 0 or y_pad < 0:\n",
    "        if x > y:\n",
    "            new_x = size\n",
    "            new_y = int(y * (size/x))\n",
    "        else:\n",
    "            new_y = size\n",
    "            new_x = int(x * (size/y))\n",
    "        img = np.array(Image.fromarray(img).resize((new_y, new_x)))\n",
    "        x,y = img.shape\n",
    "        x_pad = size - x\n",
    "        y_pad = size - y\n",
    "    # pad the image\n",
    "    if x_pad > 0 or y_pad > 0:\n",
    "        x_pad1, x_pad2 = x_pad//2, x_pad-x_pad//2\n",
    "        y_pad1, y_pad2 = y_pad//2, y_pad-y_pad//2\n",
    "        img = np.pad(img, ((x_pad1, x_pad2), (y_pad1, y_pad2)), 'constant')\n",
    "    return img\n",
    "\n",
    "# Function that takes a folder and pads each image in the folder. Inputs are the input path, output path.\n",
    "def pad_folder(input_path, output_path, size):\n",
    "    # make the output path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    subfolders = [f.path for f in os.scandir(input_path) if f.is_dir()]\n",
    "    for folder in subfolders:\n",
    "        # use base folder name as class\n",
    "        class_name = os.path.basename(folder)\n",
    "        # make the output class folder\n",
    "        os.makedirs(os.path.join(output_path, class_name), exist_ok=True)\n",
    "        # get all the images in the folder\n",
    "        images = [f.path for f in os.scandir(folder) if f.is_file()]\n",
    "        for img in images:\n",
    "            # input image path\n",
    "            img_in_path = img\n",
    "            # output image path\n",
    "            img_out_path = os.path.join(output_path, class_name, os.path.basename(img))\n",
    "            img_out_path = img_out_path.replace('.tif', '.bmp')\n",
    "            # print statment\n",
    "            print(f\"Padding {img_in_path} to {img_out_path}\")\n",
    "            # pad the image and save it\n",
    "            try:\n",
    "                img_output = pad_image(image=img_in_path, size=size)\n",
    "                # write img as bmp\n",
    "                im = Image.fromarray(img_output)\n",
    "                im.save(img_out_path)\n",
    "            except Exception as e:\n",
    "                print(\"failed to pad image\", img_in_path, e)\n",
    "pad_folder(input_path='datasets/testing', output_path=\"datasets/padded_testing\", size=256)\n",
    "pad_folder(input_path='datasets/training', output_path=\"datasets/padded_training\", size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
